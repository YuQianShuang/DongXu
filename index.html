<!DOCTYPE html>  
<html>  
    <head>  
        <title></title>  
    </head>  
    <body>  
        <pre>
            import pandas as pd  
            from sklearn.model_selection import train_test_split, StratifiedKFold  
            from sklearn.preprocessing import StandardScaler, LabelEncoder  
            from sklearn.ensemble import RandomForestRegressor  
            from sklearn.metrics import mean_squared_error, make_scorer  
from sklearn.tree import export_graphviz  
import matplotlib.pyplot as plt  
import seaborn as sns  
import numpy as np  
  
# 读取CSV数据  
data = pd.read_csv('data.csv')  
  
# 统计画画直方图，看数据分布  
sns.histplot(data['target'], bins=30, kde=True)  
plt.title('Target Distribution')  
plt.xlabel('Target')  
plt.ylabel('Frequency')  
plt.show()  
  
# 划分训练集和测试集  
X = data.drop('target', axis=1)  
y = data['target']  
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  
  
# 平衡阴阳样本  
le = LabelEncoder()  
y_train = le.fit_transform(y_train)  
y_test = le.transform(y_test)  
  
# 特征工程  
X_train = X_train.apply(lambda x: x.astype(float).fillna(0))  
X_test = X_test.apply(lambda x: x.astype(float).fillna(0))  
X_train = X_train.apply(lambda x: np.log(x + 1) if x.dtype == 'float' else x)  
X_test = X_test.apply(lambda x: np.log(x + 1) if x.dtype == 'float' else x)  
  
# 归一化  
scaler = StandardScaler()  
X_train = scaler.fit_transform(X_train)  
X_test = scaler.transform(X_test)  
  
# 挑选模型并对其进行训练和评估  
model = RandomForestRegressor()  
model.fit(X_train, y_train)  
predictions = model.predict(X_test)  
rmse = np.sqrt(mean_squared_error(y_test, predictions))  
print(f'Root Mean Squared Error: {rmse}')  
  
# 可视化呈现结果  
sns.lineplot(x='iteration', y='target', data=pd.DataFrame(data['target'].values), color='blue') # 用seaborn绘制回归结果曲线图，此处需要提供具体的迭代次数（iteration）列以及目标变量（target）列的数据，可以将其替换为您的实际数据列名。</pre>  
    </body>  
</html>
